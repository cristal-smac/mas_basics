{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# La théorie du bien-être social\n",
    "\n",
    "Le problème présenté ici rentre dans le cadre de l'affectation de ressources à un certain nombre d'agents. On a un ensemble de ressources et un ensemble d'agents à qui l'on doit distribuer ces ressources. Chaque agent étant autonome, il n'accorde pas la même importance aux différentes ressources que ses congénères. Pour mesurer la satisfaction d'un agent lors de la possession d'un certain nombre de ressources on utilise ici une fonction d'utilité qui, pour chaque ressource, indique la valeur que l'agent lui accorde. D'autres considérations pourraient être prises en compte, nous restons dans un cadre simple. Quand les utilités sont additives, ce qui sera le cas ici, le bien-être individuel d'un agent est alors la somme des utilités qu'il accorde aux ressources qu'il possède.\n",
    "Mais la collectivité doit aussi s'accorder sur une mesure de bien-être. Pour mesurer le bien-être social, il existe 4 grandes méthodes classiques:\n",
    "\n",
    "- Utilitaire : maximiser la somme des utilités de chaque agent\n",
    "- Egalitaire : maximiser le minimum\n",
    "- Elitiste : maximiser le maximum\n",
    "- ressource de Nash : maximiser le ressource\n",
    "\n",
    "Le problème consiste alors à trouver comment affecter l'ensemble des ressources aux différents agents de manière à maximiser le bien-être social choisi.\n",
    "\n",
    "Cette feuille montre comment, à l'aide d'une approche comportementale, il est possible de s'approcher voire de calculer l'optimum social.\n",
    "\n",
    "### Comment coder ressources et fonctions d'utilité\n",
    "\n",
    "Afin de pouvoir jouer sur les nombres de ressources et/ou d'agents, nous générerons aléatoirement des noms de ressources afin de pouvoir en avoir autant que l'on souhaite.  Pour la fonction d'utilité, on utilisera un dictionnaire Python, donc les clés sont les articles potentiels et les valeurs le poids que l'agent accorde à cette clé. Pour ces valeurs on prendra un entier naturel (donc sans le zero). Par convention, plus il sera important, plus l'agent accordera de la valeur à cet article.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "import functools\n",
    "import numpy as np\n",
    "\n",
    "nb_resources =10                        # nb de ressources souhaités\n",
    "valeurs = list(range(1,20))  # intervalle de valuation de chaque ressource\n",
    "\n",
    "def genere_nom():\n",
    "    return ''.join(random.choice(string.ascii_uppercase) for _ in range(5))\n",
    "   \n",
    "# Generer une liste de ressources\n",
    "ressources = [genere_nom() for _ in range(nb_resources)]\n",
    "print(\"Un ensemble de ressources \\t\", ressources)\n",
    "\n",
    "# Creer une fonction d'utilité avec des valeurs aléatoires\n",
    "u = {r : random.choice(valeurs) for r in ressources}\n",
    "print(\"Une fonction d'utilité\\t\" , u)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# On passe aux agents\n",
    "Un agent est défini avec le `bag` de ressources qu'il possède et une fonction d'utilité `fUtil` lui permettant de l'évaluer.\n",
    "Lors de sa création, la fonction d'évalution de l'agent est définie aléatoirement. Le bag est initialement vide. La méthode `welfare` permet de connaître le bien-être individuel de l'agent, ou en d'autres termes, comment l'agent évalue son bag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self,name) :\n",
    "        self.name=name\n",
    "        self.fUtil = {r : random.choice(valeurs) for r in ressources}\n",
    "        self.bag = []\n",
    "    def __str__(self) :\n",
    "        return \"agent \"+self.name+\"  \"+ str(len(self.bag)) + \" ressources. welfare à \"+ str(self.welfare())\n",
    "    def welfare(self):\n",
    "        return sum([self.fUtil.get(r) for r in self.bag]) \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quelques manipulations basiques sur un agent pour s'entrainer ;-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=Agent(\"ag\")\n",
    "a.bag=random.sample(ressources,5) # choices : avec remplacement ; sample : sans remplacement\n",
    "\n",
    "# le bag de l'agent a\n",
    "print(\"Bag \\t\\t\", a.bag)                              # ou sorted(a.bag)\n",
    "\n",
    "# la fonction d'utilité de l'agent a\n",
    "print(\"fUtil \\t\\t\", a.fUtil)                        # ou dict(sorted(a.fUtil.items()))\n",
    "\n",
    "# le bien-être de l'agent a\n",
    "print(\"welfare \\t\", a.welfare())\n",
    "\n",
    "# le bag avec ses valeurs\n",
    "bv = [ (r,a.fUtil.get(r)) for r in a.bag]\n",
    "print(\"bag valué \\t\" , bv )\n",
    "\n",
    "# le bag valué , trié par ordre croissant des valeurs\n",
    "print(\"bag valué trié \\t\", sorted(bv, key=lambda x: x[1]) )\n",
    "\n",
    "# les ressources, triées par valuation (la premier est celle dont on se débarrasse le plus facilement\n",
    "print(\"ressourc triées\\t\",  [r for r,_ in sorted(bv, key=lambda x: x[1])]    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut maintenant créer autant d'agents que l'on souhaite, leur affecter des ressources et calculer leur bien-être individuel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creer 5 agents\n",
    "agentList = [Agent(\"ag\"+str(i)) for i in range(5) ]\n",
    " \n",
    "# distribuer les ressources aléatoirement\n",
    "for i in range(len(ressources)) :\n",
    "    random.choice(agentList).bag.append(ressources[i])\n",
    "\n",
    "# afficher les agents\n",
    "for a in agentList:\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approche centralisée\n",
    "Maintenant que les agents ont un `bag` rempli, il est maintenant possible de calculer le bien-être de cette société d'agents.\n",
    "Le calcul du bien-être social consiste à appliquer une opération spécifique (selon la fonction de bien-être souhaitée) à la valuation du bag de chaque agent. Pour le bien-être-social utilitaire c'est par exemple une somme.\n",
    "\n",
    "| nom | fn à maximiser |\n",
    "-----| ----|\n",
    "| utilitaire | somme |\n",
    "| égaltaire | min |\n",
    "| élististe | max |\n",
    "| Nash | produit |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " print('Utilitaire\\t', functools.reduce(lambda a, b: sum([a,b]) , [a.welfare() for a in agentList]) )\n",
    " print('Egalitaire\\t', functools.reduce(lambda a, b: min([a,b]) , [a.welfare() for a in agentList]) )\n",
    " print('Elitiste\\t',   functools.reduce(lambda a, b: max([a,b]) , [a.welfare() for a in agentList]) )\n",
    " print('ressource Nash\\t', functools.reduce(lambda a, b: np.prod([a,b]) , [a.welfare() for a in agentList]) )\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notion d'optimal social\n",
    "\n",
    "Parmi toutes les affectations possibles de différentes ressources, certaines fournissent la valeur maximale possible à la fonction de bien-être social. Pour certains bien-être sociaux cette affectation est facile à calculer (elististe, utilitaire) , pour d'autres c'est beaucoup plus compliqué. De plus, on considère ici qu'une \"main invisible\" (clin d'oeil à [Adam Smith](https://fr.wikipedia.org/wiki/Main_invisible)) distribue les ressources comme par magie, si on prenait en compte les relations sociales entre les agents, cela devient compliqué même pour les fonctions les plus simples.\n",
    "\n",
    "##### Solution optimale pour le bien-être social élitiste\n",
    "Le bien-être social **élitiste** consiste à **maximiser la richesse du plus riche** des agents (tout donner à son \"champion\" en quelque sorte). Quand aucune utilité n'est négative, calculer cet optimal est facile puisqu'il suffit de donner tous les ressources à l'agents qui valorise le mieux la totalité des ressources.\n",
    "La \"main invisible\" affecte tour à tour tous les produis à chaque agent, et regarde qui est au bien-être maximum (on pourrait imaginer faire la somme des valuations de la fonction d'utilité sans affecter les ressources, mais cela ne fonctionnerait que si une ressource n'apparaît qu'une et une seule fois)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in agentList:\n",
    "    a.bag = ressources.copy()\n",
    "\n",
    "# On recherche la plus forte évaluation\n",
    "index = np.argmax([a.welfare() for a in agentList])\n",
    "m = agentList[index].welfare()\n",
    "\n",
    "print(\"Elitiste. Valeur optimale : \", m,\". Obtenue en donnant tout à l'agent \",a.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Solution optimale pour le bien-être social utilitaire\n",
    "Le bien-être social **utilitaire** consiste à **maximiser la somme** des richesses de tous les agents. Quand aucune utilité n'est négative, calculer cet optimal est facile puisqu'il suffit de donner chaque ressource à l'agent qui la valorise le mieux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on réinitialise les bags\n",
    "for a in agentList :\n",
    "        a.bag=[]\n",
    "\n",
    "# on affecte les ressources 1 par 1 à l'agent qui la valorise le mieux               \n",
    "for r in ressources :\n",
    "        index = np.argmax([a.fUtil.get(r)  for a in agentList])\n",
    "        ag = agentList[index]\n",
    "        ag.bag.append(r)\n",
    "\n",
    "# On fait la somme des évaluation\n",
    "s = sum([a.welfare() for a in agentList])\n",
    "\n",
    "print(\"Utilitaire. Valeur optimale : \", s ,\" obtenue avec les affectations \")\n",
    "for a in agentList :\n",
    "        print(a, a.bag)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Solution optimale pour les bien-êtres égalitaires ou nash\n",
    "Cette fois il n'y a pas de solution simple, même pour une \"main invisible\". Il faudrait tester toutes les allocations possibles. Avec `n` agents et `r` ressources il existe `n^r` affectations possibles (si on a 10 agents et 100 ressources cela fait 10^100 tests, ce qui est hors de portée des ordinateurs actuels).\n",
    "On peut alors éventuellement utiliser des méthodes approximatives type Monte-Carlo ou Algorithme génétique, mais rien ne garantit l'optimalité du résultat.\n",
    "\n",
    "Ci-dessous une méthode de monte-carlo pour le bien-être de Nash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestWelfare=-1\n",
    "bestAlloc=[]\n",
    "for i in range(100000):\n",
    "    # on réinitialise les bags\n",
    "    for a in agentList :\n",
    "        a.bag=[]\n",
    "    # on affecte les ressources au hasard\n",
    "    for r in ressources :\n",
    "        a = random.choice(agentList)\n",
    "        a.bag.append(r)\n",
    "    # On compare le resultat à la meilleure situation connue\n",
    "    p = np.prod([a.welfare() for a in agentList])  # sum,prod,min,max\n",
    "    if (p > bestWelfare):\n",
    "        bestWelfare=p\n",
    "        bestAlloc = {a.name:a.bag for a in agentList}\n",
    "        \n",
    "print(\"Meilleure allocation\",bestWelfare,bestAlloc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Une approche multi-agents\n",
    "\n",
    "L'approche centralisée présente un certain nombre de défauts :\n",
    "- Avoir une affectation optimale par cette technique n'est pas toujours possible (voir ci-dessus). \n",
    "- Cette technique oblige tous les agents à indiquer à l'organe central de calcul toutes leurs utilités. La garantie d'une certaine privacité est pourtant parfois necessaire\n",
    "- La \"main invisible\" ! L'approche centralisée prend difficilement en compte le fait que les agents ne se connaissent pas forcément tous. Dans la vraie vie, les connaissances des individus dessinent un graphe social \n",
    "\n",
    "\n",
    "Nous étudions par la suite une approche comportementale qui permet aux agents d'échanger des ressources pour améliorer le bien-être social. Chaque agent tour à tour peut effectuer certains échanges avec ces accointances fidèles à un type de réseau social. On peut alors voir peu à peu le bien-être social évoluer. L'important maintenant, n'est plus \"quel est l'optimum ?\", mais \"comment on arrive à l'optimum ?\".\n",
    "\n",
    "\n",
    "##### Tout d'abord réalisons le SMA, le réseau social et l'agent ... \n",
    "- Cette fois, c'est le SMA qui crée les agents, dans son constructeur.\n",
    "- Les agents sont initialement créés vides.\n",
    "- Des méthodes permettent d'affecter aux agents des accointances ou des ressources. Ceci permettra pas la suite de relancer le même SMA soit avec la même affectation de ressources, soit avec le même réseau social, soit les deux."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Le réseau social\n",
    "\n",
    "Comme dans [mas_basics]() on utilisera la librairie networkx qui contient de nombreuses fonctions de création de graphes et permet de récupérer avec sa fonction `to_numpy_array` une matrice d'adjacence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "nb_nodes = 20\n",
    "# graph = nx.barabasi_albert_graph(nb_nodes, 2)\n",
    "graph = nx.complete_graph(nb_nodes)\n",
    "#graph = nx.erdos_renyi_graph(nb_nodes,0.1)\n",
    "#graph = nx.cycle_graph(nb_nodes)\n",
    "#graph = nx.random_regular_graph(3,nb_nodes)\n",
    "matrix = nx.to_numpy_array(graph, nodelist=range(nb_nodes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Et pour la représentation graphique ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10,5))    # pour définir la taille de la figure\n",
    "nx.draw_networkx(graph)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### L'agent et le SMA\n",
    "Pour créer un SMA on lui passe simplement le nombre d'agent souhaité. C'est le SMA qui crée les agents. Les methodes setRessources et setAccointances permettent respectivement d'affecter les agents avec une affectation des ressources aux agents sous forme d'une liste de listes, et une matrice d'adjacence sous forme d'une liste de listes (obtenue facilement à partir d'un graphe networkx).\n",
    "L'agent est initialement créé sans accointances ni ressources, mais il a déjà sa fonction d'utilité.\n",
    "Attention : recréer un SMA recrée aussi les fonctions d'utilité de chacun !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SMA:\n",
    "    def __init__(self, nb_agents):\n",
    "        self.agentList = [Agent(i) for i in range(nb_agents)]\n",
    "        self.welfare_types=''    # 'Utilitarist' # 'Egalitarist','Utilitarist','Elitist',''Nash'\n",
    "        \n",
    "\n",
    "    def setRessources(self,init_affect) :\n",
    "        if (len(init_affect) != len(self.agentList)) :\n",
    "            print(\"Problem of size in setRessources :\", len(init_affect), len(agentList))\n",
    "            exit()\n",
    "        for i in range(len(self.agentList)) :\n",
    "            self.agentList[i].bag=init_affect[i]\n",
    "\n",
    "    def setAccointances(self,adjacency_matrix) :\n",
    "        if (len(adjacency_matrix[0]) != len(self.agentList)) :\n",
    "            print(\"Problem of size in setAccointances :\", len(adjacency_matrix[0]) , len(agentList))\n",
    "            exit()\n",
    "        for i in range(len(self.agentList)) :\n",
    "            self.agentList[i].accointances = np.nonzero(adjacency_matrix[i])[0]\n",
    "\n",
    "    def run(self, rounds):\n",
    "        self.tick=0\n",
    "        self.history=[]\n",
    "        self.history.append(self.socialWelfare())\n",
    "        for i in range(0,rounds):\n",
    "            self.runOnce()\n",
    "            self.history.append(self.socialWelfare())\n",
    "\n",
    "    def runOnce(self):\n",
    "        self.tick += 1\n",
    "        for agent in self.agentList:\n",
    "            agent.decide(self.tick)\n",
    "        print(\"tick \" + str(self.tick) + \" ended\")\n",
    "        print(\"Le Welfare actuel est de \", self.socialWelfare())\n",
    "\n",
    "    def socialWelfare(self):\n",
    "        if self.welfare_type=='Egalitarist':\n",
    "            return sum([a.welfare() for a in self.agentList])\n",
    "        elif self.welfare_type=='Utilitarist':\n",
    "            return min([a.welfare() for a in self.agentList])\n",
    "        elif self.welfare_type=='Elitist':\n",
    "            return max([a.welfare() for a in self.agentList])\n",
    "        elif self.welfare_type=='Nash':\n",
    "            return np.prod([a.welfare() for a in self.agentList])\n",
    "        else :\n",
    "            print(\"Unknown method in socialWelfare\")\n",
    "            exit()\n",
    "\n",
    "\n",
    "\n",
    "# l'agent est le même que précédemment excepté qu'il a maintenant ses propres accointances, sa fonction d'Utilité\n",
    "# et une méthode de décision avec différents échanges possibles\n",
    "# par défaut il n'a ni ressources ni accointances (c'est le SMA qui lui donne)\n",
    "class Agent:\n",
    "    def __init__(self,name) :\n",
    "        self.name=name\n",
    "        self.fUtil = {r : random.choice(valeurs) for r in ressources}\n",
    "        self.bag = []\n",
    "        self.accointances = []\n",
    "    def __str__(self) :\n",
    "        return \"agent \"+self.name+\"  \"+ str(len(self.bag)) + \" ressources. Welfare à \"+ str(self.welfare())\n",
    "    def welfare(self):\n",
    "        return sum([self.fUtil.get(r) for r in self.bag])\n",
    "    def getSortedBag(self):\n",
    "        bagval = [ (r,self.fUtil.get(r)) for r in self.bag]\n",
    "        return [r for r,_ in sorted(bagval, key=lambda x: x[1])]\n",
    "\n",
    "    def gift(self):    \n",
    "        # choisir une accointance au hasard\n",
    "        friend = sma.agentList[np.random.choice(self.accointances)]\n",
    "        # choisir une de ses propres ressources au hasard\n",
    "        r = np.random.choice(self.bag)\n",
    "        # donner cette ressource à l'accointance\n",
    "        self.bag.remove(r)\n",
    "        friend.bag.append(r)\n",
    "        print(self.name, \"donne la ressource \",r,\" à l'agent \",friend.name)\n",
    "\n",
    "    # swap sans aucune contrainte\n",
    "    def swap1(self):\n",
    "        # choisir une accointance au hasard\n",
    "        friend = sma.agentList[np.random.choice(self.accointances)]\n",
    "        # choisir une de ses propres ressources au hasard\n",
    "        r = np.random.choice(self.bag)\n",
    "        # choisir une des ressources de l'autre au hasard\n",
    "        if len(friend.bag)==0 :\n",
    "            return\n",
    "        s = np.random.choice(friend.bag)\n",
    "        # echanger les ressources\n",
    "        self.bag.remove(r)\n",
    "        friend.bag.remove(s)\n",
    "        friend.bag.append(r)\n",
    "        self.bag.append(s)\n",
    "        print(self.name, \"echange \",r,\" contre \",s, \" avec \",friend.name)\n",
    "    \n",
    "    # swap uniquement si socialwelfare augmente\n",
    "    def swap2(self) :\n",
    "        # chercher s'il existe 2 ressources à échanger\n",
    "        # on échange uniquement si le socialWelfare augmente\n",
    "        # idealement il faudrait parcourir les miennes par intérêt décroissant (donc valeur croissante)\n",
    "        # en utilisant getSortedBag()\n",
    "        for r in self.bag :\n",
    "            for friend in self.accointances :\n",
    "                for s in  friend.bag :\n",
    "                    # on teste si c'est mieux pour les deux\n",
    "                    # OBLIGE A TOUT CONNAITRE, CE QUI N'EST PAS TRES \"AGENT\" MAIS DES CRITERES LOCAUX EXISTENT\n",
    "                    actualWelfare = sma.socialWelfare()\n",
    "                    self.bag.remove(r)\n",
    "                    friend.bag.remove(s)\n",
    "                    friend.bag.append(r)\n",
    "                    self.bag.append(s)\n",
    "                    if sma.socialWelfare() > actualWelfare :\n",
    "                        print(self.name, \"echange \",r,\" contre \",s, \" avec \",friend.name)\n",
    "                        print(\"Welfare passe de \",actualWelfare,\" à \",sma.socialWelfare())\n",
    "                        return\n",
    "                    else :\n",
    "                        # on remet tout en place\n",
    "                        self.bag.remove(s)\n",
    "                        friend.bag.remove(r)\n",
    "                        friend.bag.append(s)\n",
    "                        self.bag.append(r)\n",
    "                       \n",
    " \n",
    "\n",
    "    def decide(self,tick):\n",
    "        # pour faire qq chose il faut au moins avoir des ressources et des amis\n",
    "        if (len(self.accointances)==0 or len(self.bag)==0) :\n",
    "            return\n",
    "        behavior = 1 #random.randint(0,1)\n",
    "        # s'écrit avec match-case à partir de python 3.10\n",
    "        if   behavior==0 : self.gift()\n",
    "        elif behavior==1 : self.swap1()\n",
    "        elif behavior==2 : self.swap2()\n",
    "        else : \n",
    "                print(\"Impossible behavior in decide\")\n",
    "                exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Une expérience\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_agents=5\n",
    "# une affectation aléatoire\n",
    "l=[[] for i in range(nb_agents)]\n",
    "for r in ressources :\n",
    "    l[random.randrange(nb_agents)].append(r)\n",
    "\n",
    "# un graphe aléatoire\n",
    "graph = nx.erdos_renyi_graph(nb_agents,0.1)\n",
    "m = nx.to_numpy_array(graph, nodelist=range(nb_agents))\n",
    "\n",
    "# L'experience\n",
    "sma = SMA(nb_agents)\n",
    "sma.setAccointances(m)\n",
    "sma.setRessources(l)\n",
    "\n",
    "sma.welfare_type='Nash'\n",
    "sma.run(10)\n",
    "\n",
    "print(\"Final Social Welfare : \", sma.socialWelfare())\n",
    "print(\"Best Social Welfare : \", max(sma.history))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tracé de l'évolution du social welfare\n",
    "Une fois l'expérience réalisée, il est alors possible de tracer l'évolution du social Welfare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sma.history)\n",
    "plt.plot(sma.history, \"-o\")\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### N expériences\n",
    "Comme le hasard intervient dans chaque expérience (distribution initiale des ressources, graphe s'il n'est pas complet), il est important de pouvoir répérer les mesures afin de moyenner les résultats. \n",
    "\n",
    "On montre ici comment calculer 100 expériences d'un graphe Erdos-Renyi avec un bien-être social Utilitaire pour 5 agents et 20 ressources. On change les affectations initiales de ressources mais pas le graphe, les maximums sont donc comparables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import string\n",
    "import functools\n",
    "import networkx as nx\n",
    "\n",
    "def genere_nom():\n",
    "    return ''.join(random.choice(string.ascii_uppercase) for _ in range(5))\n",
    "\n",
    "\n",
    "nb_resources = 20\n",
    "ressources = [genere_nom() for _ in range(nb_resources)]\n",
    "valeurs = list(range(1,20))\n",
    "nb_agents = 5 \n",
    "\n",
    "# une nouvelle matrice d'adjacence\n",
    "graph = nx.erdos_renyi_graph(nb_agents,0.1)\n",
    "m = nx.to_numpy_array(graph, nodelist=range(nb_agents))\n",
    "\n",
    "result=[]\n",
    "sma = SMA(nb_agents)\n",
    "sma.welfare_type='Nash'\n",
    "for i in range(100):\n",
    "    # Affectation initiale aléatoire\n",
    "    l=[[] for i in range(nb_agents)]\n",
    "    for r in ressources :\n",
    "        l[random.randrange(nb_agents)].append(r)\n",
    "\n",
    "    # une experience : SURTOUT NE PAS RECREER LE SMA\n",
    "    sma.setAccointances(m)\n",
    "    sma.setRessources(l)\n",
    "    sma.run(100)\n",
    "    result.append(max(sma.history))\n",
    "\n",
    "# ATTENTION : 1mn de calcul\n",
    "print(result)\n",
    "print(\"Maximum obtenu : \", max(result), \"En moyenne : \",np.mean(result))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On montre maintenant comment calculer 100 expériences d'un graphe Erdos-Renyi avec un bien-être social Egalitaire pour 5 agents et 20 ressources. A chaque experience on change le graphe mais pas les affectations initiales de ressources. Les maximums ne sont pas comparables entre eux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_resources = 20\n",
    "ressources = [genere_nom() for _ in range(nb_resources)]\n",
    "valeurs = list(range(1,20))\n",
    "nb_agents = 5 \n",
    "\n",
    "# Affectation initiale aléatoire\n",
    "l=[[] for i in range(nb_agents)]\n",
    "for r in ressources :\n",
    "    l[random.randrange(nb_agents)].append(r)\n",
    "\n",
    "result=[]\n",
    "sma = SMA(nb_agents)\n",
    "sma.welfare_type='Nash'\n",
    "for i in range(100):\n",
    "    # une nouvelle matrice d'adjacence\n",
    "    graph = nx.erdos_renyi_graph(nb_agents,0.1)\n",
    "    m = nx.to_numpy_array(graph, nodelist=range(nb_agents))\n",
    "    # une experience : SURTOUT NE PAS RECREER LE SMA\n",
    "    sma.setAccointances(m)\n",
    "    sma.setRessources(l)\n",
    "    sma.run(100)\n",
    "    result.append(max(sma.history))\n",
    "\n",
    "# ATTENTION : 1mn de calcul\n",
    "print(result)\n",
    "print(\"Maximum obtenu : \", max(result), \"En moyenne : \",np.mean(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercices\n",
    "### Exercices faciles\n",
    "\n",
    "Maintenant que les choses sont en place, il est possible de jouer sur de nombreux paramètres\n",
    "1. le type de comportement utilisé (1). \n",
    "    - Actuellement l'agent précédent est un agent rationnel : il accepte un échange si son bien-être individuel augmente. \n",
    "      Que donnent les résultats si il devient social, c'est à dire qu'il n'accepte un échange que si le bien être social augmente ? \n",
    "      (Attention : Ceci necessite de trouver un critère entre les deux agents permettant d'être certain que le niveau de la société augmente \n",
    "      (trivial pour Egalitarist ou Elitist) )  \n",
    "1. le type de comportement utilisé (2). \n",
    "    - Actuellement l'agent précédent teste un échange en priorité \"ressources\" (je choisis une ressource et j'essaye d'échanger \n",
    "      cette ressource avec tous les amis avant de changer de ressource). Que donne le contraire ?\n",
    "\n",
    "### Exercices plus difficiles    \n",
    "1. le bien-être social étudié\n",
    "    - Précédemment, nous avons présenté 4 mesures de bien-être social. Que donne le Leximin ? Le leximin consiste à maximiser dans l'ordre lexicographique les vecteurs des utilités de chaque agent classées du min au max\n",
    "1. le type de graphe\n",
    "    - Est-ce que des phénomènes spécifiques se produisent selon la forme du graphe ou le taux de connectivité moyen ?\n",
    "1. le type d'échange accepté\n",
    "    - Actuellement il n'y a que des échanges de taille 0 ou 1. Qu'est-ce que cela change d'accepter des échanges de 2 ou 3 ressources en même temps ?\n",
    "1. Les agents sont pour l'instant tous homogènes. Ils appliquent tous le même comportement. Qu'est-ce que ça donne si la population est hétérogène ?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bibliographie\n",
    "- Moulin, H. (2004). Fair division and collective welfare. MIT press.\n",
    "- Chevaleyre Y, Endriss U, Lang J, Maudet N (2005) Negotiating over small bundles of resources. In: AAMAS’05, pp 296–302\n",
    "- Nongaillard, A., & Mathieu, P. (2014). Agent-based reallocation problem on social networks. Group Decision and Negotiation, 23(5), 1067-1083.\n",
    "- Delahaye, J. P., & Mathieu, P. (2009). La répartition idéale des biens existe-t-elle?. Pour la science, 381, 88-93.\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
